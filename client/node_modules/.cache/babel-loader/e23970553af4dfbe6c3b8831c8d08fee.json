{"ast":null,"code":"/*\n * Copyright (C) 2016 Bilibili. All Rights Reserved.\n *\n * @author zheng qian <xqq@xqq.im>\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport Log from '../utils/logger.js';\nimport MP4 from './mp4-generator.js';\nimport AAC from './aac-silent.js';\nimport Browser from '../utils/browser.js';\nimport { SampleInfo, MediaSegmentInfo, MediaSegmentInfoList } from '../core/media-segment-info.js';\nimport { IllegalStateException } from '../utils/exception.js'; // Fragmented mp4 remuxer\n\nclass MP4Remuxer {\n  constructor(config) {\n    this.TAG = 'MP4Remuxer';\n    this._config = config;\n    this._isLive = config.isLive === true ? true : false;\n    this._dtsBase = -1;\n    this._dtsBaseInited = false;\n    this._audioDtsBase = Infinity;\n    this._videoDtsBase = Infinity;\n    this._audioNextDts = undefined;\n    this._videoNextDts = undefined;\n    this._audioStashedLastSample = null;\n    this._videoStashedLastSample = null;\n    this._audioMeta = null;\n    this._videoMeta = null;\n    this._audioSegmentInfoList = new MediaSegmentInfoList('audio');\n    this._videoSegmentInfoList = new MediaSegmentInfoList('video');\n    this._onInitSegment = null;\n    this._onMediaSegment = null; // Workaround for chrome < 50: Always force first sample as a Random Access Point in media segment\n    // see https://bugs.chromium.org/p/chromium/issues/detail?id=229412\n\n    this._forceFirstIDR = Browser.chrome && (Browser.version.major < 50 || Browser.version.major === 50 && Browser.version.build < 2661) ? true : false; // Workaround for IE11/Edge: Fill silent aac frame after keyframe-seeking\n    // Make audio beginDts equals with video beginDts, in order to fix seek freeze\n\n    this._fillSilentAfterSeek = Browser.msedge || Browser.msie; // While only FireFox supports 'audio/mp4, codecs=\"mp3\"', use 'audio/mpeg' for chrome, safari, ...\n\n    this._mp3UseMpegAudio = !Browser.firefox;\n    this._fillAudioTimestampGap = this._config.fixAudioTimestampGap;\n  }\n\n  destroy() {\n    this._dtsBase = -1;\n    this._dtsBaseInited = false;\n    this._audioMeta = null;\n    this._videoMeta = null;\n\n    this._audioSegmentInfoList.clear();\n\n    this._audioSegmentInfoList = null;\n\n    this._videoSegmentInfoList.clear();\n\n    this._videoSegmentInfoList = null;\n    this._onInitSegment = null;\n    this._onMediaSegment = null;\n  }\n\n  bindDataSource(producer) {\n    producer.onDataAvailable = this.remux.bind(this);\n    producer.onTrackMetadata = this._onTrackMetadataReceived.bind(this);\n    return this;\n  }\n  /* prototype: function onInitSegment(type: string, initSegment: ArrayBuffer): void\n     InitSegment: {\n         type: string,\n         data: ArrayBuffer,\n         codec: string,\n         container: string\n     }\n  */\n\n\n  get onInitSegment() {\n    return this._onInitSegment;\n  }\n\n  set onInitSegment(callback) {\n    this._onInitSegment = callback;\n  }\n  /* prototype: function onMediaSegment(type: string, mediaSegment: MediaSegment): void\n     MediaSegment: {\n         type: string,\n         data: ArrayBuffer,\n         sampleCount: int32\n         info: MediaSegmentInfo\n     }\n  */\n\n\n  get onMediaSegment() {\n    return this._onMediaSegment;\n  }\n\n  set onMediaSegment(callback) {\n    this._onMediaSegment = callback;\n  }\n\n  insertDiscontinuity() {\n    this._audioNextDts = this._videoNextDts = undefined;\n  }\n\n  seek(originalDts) {\n    this._audioStashedLastSample = null;\n    this._videoStashedLastSample = null;\n\n    this._videoSegmentInfoList.clear();\n\n    this._audioSegmentInfoList.clear();\n  }\n\n  remux(audioTrack, videoTrack) {\n    if (!this._onMediaSegment) {\n      throw new IllegalStateException('MP4Remuxer: onMediaSegment callback must be specificed!');\n    }\n\n    if (!this._dtsBaseInited) {\n      this._calculateDtsBase(audioTrack, videoTrack);\n    }\n\n    this._remuxVideo(videoTrack);\n\n    this._remuxAudio(audioTrack);\n  }\n\n  _onTrackMetadataReceived(type, metadata) {\n    let metabox = null;\n    let container = 'mp4';\n    let codec = metadata.codec;\n\n    if (type === 'audio') {\n      this._audioMeta = metadata;\n\n      if (metadata.codec === 'mp3' && this._mp3UseMpegAudio) {\n        // 'audio/mpeg' for MP3 audio track\n        container = 'mpeg';\n        codec = '';\n        metabox = new Uint8Array();\n      } else {\n        // 'audio/mp4, codecs=\"codec\"'\n        metabox = MP4.generateInitSegment(metadata);\n      }\n    } else if (type === 'video') {\n      this._videoMeta = metadata;\n      metabox = MP4.generateInitSegment(metadata);\n    } else {\n      return;\n    } // dispatch metabox (Initialization Segment)\n\n\n    if (!this._onInitSegment) {\n      throw new IllegalStateException('MP4Remuxer: onInitSegment callback must be specified!');\n    }\n\n    this._onInitSegment(type, {\n      type: type,\n      data: metabox.buffer,\n      codec: codec,\n      container: \"\".concat(type, \"/\").concat(container),\n      mediaDuration: metadata.duration // in timescale 1000 (milliseconds)\n\n    });\n  }\n\n  _calculateDtsBase(audioTrack, videoTrack) {\n    if (this._dtsBaseInited) {\n      return;\n    }\n\n    if (audioTrack.samples && audioTrack.samples.length) {\n      this._audioDtsBase = audioTrack.samples[0].dts;\n    }\n\n    if (videoTrack.samples && videoTrack.samples.length) {\n      this._videoDtsBase = videoTrack.samples[0].dts;\n    }\n\n    this._dtsBase = Math.min(this._audioDtsBase, this._videoDtsBase);\n    this._dtsBaseInited = true;\n  }\n\n  flushStashedSamples() {\n    let videoSample = this._videoStashedLastSample;\n    let audioSample = this._audioStashedLastSample;\n    let videoTrack = {\n      type: 'video',\n      id: 1,\n      sequenceNumber: 0,\n      samples: [],\n      length: 0\n    };\n\n    if (videoSample != null) {\n      videoTrack.samples.push(videoSample);\n      videoTrack.length = videoSample.length;\n    }\n\n    let audioTrack = {\n      type: 'audio',\n      id: 2,\n      sequenceNumber: 0,\n      samples: [],\n      length: 0\n    };\n\n    if (audioSample != null) {\n      audioTrack.samples.push(audioSample);\n      audioTrack.length = audioSample.length;\n    }\n\n    this._videoStashedLastSample = null;\n    this._audioStashedLastSample = null;\n\n    this._remuxVideo(videoTrack, true);\n\n    this._remuxAudio(audioTrack, true);\n  }\n\n  _remuxAudio(audioTrack, force) {\n    if (this._audioMeta == null) {\n      return;\n    }\n\n    let track = audioTrack;\n    let samples = track.samples;\n    let dtsCorrection = undefined;\n    let firstDts = -1,\n        lastDts = -1,\n        lastPts = -1;\n    let refSampleDuration = this._audioMeta.refSampleDuration;\n    let mpegRawTrack = this._audioMeta.codec === 'mp3' && this._mp3UseMpegAudio;\n    let firstSegmentAfterSeek = this._dtsBaseInited && this._audioNextDts === undefined;\n    let insertPrefixSilentFrame = false;\n\n    if (!samples || samples.length === 0) {\n      return;\n    }\n\n    if (samples.length === 1 && !force) {\n      // If [sample count in current batch] === 1 && (force != true)\n      // Ignore and keep in demuxer's queue\n      return;\n    } // else if (force === true) do remux\n\n\n    let offset = 0;\n    let mdatbox = null;\n    let mdatBytes = 0; // calculate initial mdat size\n\n    if (mpegRawTrack) {\n      // for raw mpeg buffer\n      offset = 0;\n      mdatBytes = track.length;\n    } else {\n      // for fmp4 mdat box\n      offset = 8; // size + type\n\n      mdatBytes = 8 + track.length;\n    }\n\n    let lastSample = null; // Pop the lastSample and waiting for stash\n\n    if (samples.length > 1) {\n      lastSample = samples.pop();\n      mdatBytes -= lastSample.length;\n    } // Insert [stashed lastSample in the previous batch] to the front\n\n\n    if (this._audioStashedLastSample != null) {\n      let sample = this._audioStashedLastSample;\n      this._audioStashedLastSample = null;\n      samples.unshift(sample);\n      mdatBytes += sample.length;\n    } // Stash the lastSample of current batch, waiting for next batch\n\n\n    if (lastSample != null) {\n      this._audioStashedLastSample = lastSample;\n    }\n\n    let firstSampleOriginalDts = samples[0].dts - this._dtsBase; // calculate dtsCorrection\n\n    if (this._audioNextDts) {\n      dtsCorrection = firstSampleOriginalDts - this._audioNextDts;\n    } else {\n      // this._audioNextDts == undefined\n      if (this._audioSegmentInfoList.isEmpty()) {\n        dtsCorrection = 0;\n\n        if (this._fillSilentAfterSeek && !this._videoSegmentInfoList.isEmpty()) {\n          if (this._audioMeta.originalCodec !== 'mp3') {\n            insertPrefixSilentFrame = true;\n          }\n        }\n      } else {\n        let lastSample = this._audioSegmentInfoList.getLastSampleBefore(firstSampleOriginalDts);\n\n        if (lastSample != null) {\n          let distance = firstSampleOriginalDts - (lastSample.originalDts + lastSample.duration);\n\n          if (distance <= 3) {\n            distance = 0;\n          }\n\n          let expectedDts = lastSample.dts + lastSample.duration + distance;\n          dtsCorrection = firstSampleOriginalDts - expectedDts;\n        } else {\n          // lastSample == null, cannot found\n          dtsCorrection = 0;\n        }\n      }\n    }\n\n    if (insertPrefixSilentFrame) {\n      // align audio segment beginDts to match with current video segment's beginDts\n      let firstSampleDts = firstSampleOriginalDts - dtsCorrection;\n\n      let videoSegment = this._videoSegmentInfoList.getLastSegmentBefore(firstSampleOriginalDts);\n\n      if (videoSegment != null && videoSegment.beginDts < firstSampleDts) {\n        let silentUnit = AAC.getSilentFrame(this._audioMeta.originalCodec, this._audioMeta.channelCount);\n\n        if (silentUnit) {\n          let dts = videoSegment.beginDts;\n          let silentFrameDuration = firstSampleDts - videoSegment.beginDts;\n          Log.v(this.TAG, \"InsertPrefixSilentAudio: dts: \".concat(dts, \", duration: \").concat(silentFrameDuration));\n          samples.unshift({\n            unit: silentUnit,\n            dts: dts,\n            pts: dts\n          });\n          mdatBytes += silentUnit.byteLength;\n        } // silentUnit == null: Cannot generate, skip\n\n      } else {\n        insertPrefixSilentFrame = false;\n      }\n    }\n\n    let mp4Samples = []; // Correct dts for each sample, and calculate sample duration. Then output to mp4Samples\n\n    for (let i = 0; i < samples.length; i++) {\n      let sample = samples[i];\n      let unit = sample.unit;\n      let originalDts = sample.dts - this._dtsBase;\n      let dts = originalDts - dtsCorrection;\n\n      if (firstDts === -1) {\n        firstDts = dts;\n      }\n\n      let sampleDuration = 0;\n\n      if (i !== samples.length - 1) {\n        let nextDts = samples[i + 1].dts - this._dtsBase - dtsCorrection;\n        sampleDuration = nextDts - dts;\n      } else {\n        // the last sample\n        if (lastSample != null) {\n          // use stashed sample's dts to calculate sample duration\n          let nextDts = lastSample.dts - this._dtsBase - dtsCorrection;\n          sampleDuration = nextDts - dts;\n        } else if (mp4Samples.length >= 1) {\n          // use second last sample duration\n          sampleDuration = mp4Samples[mp4Samples.length - 1].duration;\n        } else {\n          // the only one sample, use reference sample duration\n          sampleDuration = Math.floor(refSampleDuration);\n        }\n      }\n\n      let needFillSilentFrames = false;\n      let silentFrames = null; // Silent frame generation, if large timestamp gap detected && config.fixAudioTimestampGap\n\n      if (sampleDuration > refSampleDuration * 1.5 && this._audioMeta.codec !== 'mp3' && this._fillAudioTimestampGap && !Browser.safari) {\n        // We need to insert silent frames to fill timestamp gap\n        needFillSilentFrames = true;\n        let delta = Math.abs(sampleDuration - refSampleDuration);\n        let frameCount = Math.ceil(delta / refSampleDuration);\n        let currentDts = dts + refSampleDuration; // Notice: in float\n\n        Log.w(this.TAG, 'Large audio timestamp gap detected, may cause AV sync to drift. ' + 'Silent frames will be generated to avoid unsync.\\n' + \"dts: \".concat(dts + sampleDuration, \" ms, expected: \").concat(dts + Math.round(refSampleDuration), \" ms, \") + \"delta: \".concat(Math.round(delta), \" ms, generate: \").concat(frameCount, \" frames\"));\n        let silentUnit = AAC.getSilentFrame(this._audioMeta.originalCodec, this._audioMeta.channelCount);\n\n        if (silentUnit == null) {\n          Log.w(this.TAG, 'Unable to generate silent frame for ' + \"\".concat(this._audioMeta.originalCodec, \" with \").concat(this._audioMeta.channelCount, \" channels, repeat last frame\")); // Repeat last frame\n\n          silentUnit = unit;\n        }\n\n        silentFrames = [];\n\n        for (let j = 0; j < frameCount; j++) {\n          let intDts = Math.round(currentDts); // round to integer\n\n          if (silentFrames.length > 0) {\n            // Set previous frame sample duration\n            let previousFrame = silentFrames[silentFrames.length - 1];\n            previousFrame.duration = intDts - previousFrame.dts;\n          }\n\n          let frame = {\n            dts: intDts,\n            pts: intDts,\n            cts: 0,\n            unit: silentUnit,\n            size: silentUnit.byteLength,\n            duration: 0,\n            // wait for next sample\n            originalDts: originalDts,\n            flags: {\n              isLeading: 0,\n              dependsOn: 1,\n              isDependedOn: 0,\n              hasRedundancy: 0\n            }\n          };\n          silentFrames.push(frame);\n          mdatBytes += frame.size;\n          currentDts += refSampleDuration;\n        } // last frame: align end time to next frame dts\n\n\n        let lastFrame = silentFrames[silentFrames.length - 1];\n        lastFrame.duration = dts + sampleDuration - lastFrame.dts; // silentFrames.forEach((frame) => {\n        //     Log.w(this.TAG, `SilentAudio: dts: ${frame.dts}, duration: ${frame.duration}`);\n        // });\n        // Set correct sample duration for current frame\n\n        sampleDuration = Math.round(refSampleDuration);\n      }\n\n      mp4Samples.push({\n        dts: dts,\n        pts: dts,\n        cts: 0,\n        unit: sample.unit,\n        size: sample.unit.byteLength,\n        duration: sampleDuration,\n        originalDts: originalDts,\n        flags: {\n          isLeading: 0,\n          dependsOn: 1,\n          isDependedOn: 0,\n          hasRedundancy: 0\n        }\n      });\n\n      if (needFillSilentFrames) {\n        // Silent frames should be inserted after wrong-duration frame\n        mp4Samples.push.apply(mp4Samples, silentFrames);\n      }\n    } // allocate mdatbox\n\n\n    if (mpegRawTrack) {\n      // allocate for raw mpeg buffer\n      mdatbox = new Uint8Array(mdatBytes);\n    } else {\n      // allocate for fmp4 mdat box\n      mdatbox = new Uint8Array(mdatBytes); // size field\n\n      mdatbox[0] = mdatBytes >>> 24 & 0xFF;\n      mdatbox[1] = mdatBytes >>> 16 & 0xFF;\n      mdatbox[2] = mdatBytes >>> 8 & 0xFF;\n      mdatbox[3] = mdatBytes & 0xFF; // type field (fourCC)\n\n      mdatbox.set(MP4.types.mdat, 4);\n    } // Write samples into mdatbox\n\n\n    for (let i = 0; i < mp4Samples.length; i++) {\n      let unit = mp4Samples[i].unit;\n      mdatbox.set(unit, offset);\n      offset += unit.byteLength;\n    }\n\n    let latest = mp4Samples[mp4Samples.length - 1];\n    lastDts = latest.dts + latest.duration;\n    this._audioNextDts = lastDts; // fill media segment info & add to info list\n\n    let info = new MediaSegmentInfo();\n    info.beginDts = firstDts;\n    info.endDts = lastDts;\n    info.beginPts = firstDts;\n    info.endPts = lastDts;\n    info.originalBeginDts = mp4Samples[0].originalDts;\n    info.originalEndDts = latest.originalDts + latest.duration;\n    info.firstSample = new SampleInfo(mp4Samples[0].dts, mp4Samples[0].pts, mp4Samples[0].duration, mp4Samples[0].originalDts, false);\n    info.lastSample = new SampleInfo(latest.dts, latest.pts, latest.duration, latest.originalDts, false);\n\n    if (!this._isLive) {\n      this._audioSegmentInfoList.append(info);\n    }\n\n    track.samples = mp4Samples;\n    track.sequenceNumber++;\n    let moofbox = null;\n\n    if (mpegRawTrack) {\n      // Generate empty buffer, because useless for raw mpeg\n      moofbox = new Uint8Array();\n    } else {\n      // Generate moof for fmp4 segment\n      moofbox = MP4.moof(track, firstDts);\n    }\n\n    track.samples = [];\n    track.length = 0;\n    let segment = {\n      type: 'audio',\n      data: this._mergeBoxes(moofbox, mdatbox).buffer,\n      sampleCount: mp4Samples.length,\n      info: info\n    };\n\n    if (mpegRawTrack && firstSegmentAfterSeek) {\n      // For MPEG audio stream in MSE, if seeking occurred, before appending new buffer\n      // We need explicitly set timestampOffset to the desired point in timeline for mpeg SourceBuffer.\n      segment.timestampOffset = firstDts;\n    }\n\n    this._onMediaSegment('audio', segment);\n  }\n\n  _remuxVideo(videoTrack, force) {\n    if (this._videoMeta == null) {\n      return;\n    }\n\n    let track = videoTrack;\n    let samples = track.samples;\n    let dtsCorrection = undefined;\n    let firstDts = -1,\n        lastDts = -1;\n    let firstPts = -1,\n        lastPts = -1;\n\n    if (!samples || samples.length === 0) {\n      return;\n    }\n\n    if (samples.length === 1 && !force) {\n      // If [sample count in current batch] === 1 && (force != true)\n      // Ignore and keep in demuxer's queue\n      return;\n    } // else if (force === true) do remux\n\n\n    let offset = 8;\n    let mdatbox = null;\n    let mdatBytes = 8 + videoTrack.length;\n    let lastSample = null; // Pop the lastSample and waiting for stash\n\n    if (samples.length > 1) {\n      lastSample = samples.pop();\n      mdatBytes -= lastSample.length;\n    } // Insert [stashed lastSample in the previous batch] to the front\n\n\n    if (this._videoStashedLastSample != null) {\n      let sample = this._videoStashedLastSample;\n      this._videoStashedLastSample = null;\n      samples.unshift(sample);\n      mdatBytes += sample.length;\n    } // Stash the lastSample of current batch, waiting for next batch\n\n\n    if (lastSample != null) {\n      this._videoStashedLastSample = lastSample;\n    }\n\n    let firstSampleOriginalDts = samples[0].dts - this._dtsBase; // calculate dtsCorrection\n\n    if (this._videoNextDts) {\n      dtsCorrection = firstSampleOriginalDts - this._videoNextDts;\n    } else {\n      // this._videoNextDts == undefined\n      if (this._videoSegmentInfoList.isEmpty()) {\n        dtsCorrection = 0;\n      } else {\n        let lastSample = this._videoSegmentInfoList.getLastSampleBefore(firstSampleOriginalDts);\n\n        if (lastSample != null) {\n          let distance = firstSampleOriginalDts - (lastSample.originalDts + lastSample.duration);\n\n          if (distance <= 3) {\n            distance = 0;\n          }\n\n          let expectedDts = lastSample.dts + lastSample.duration + distance;\n          dtsCorrection = firstSampleOriginalDts - expectedDts;\n        } else {\n          // lastSample == null, cannot found\n          dtsCorrection = 0;\n        }\n      }\n    }\n\n    let info = new MediaSegmentInfo();\n    let mp4Samples = []; // Correct dts for each sample, and calculate sample duration. Then output to mp4Samples\n\n    for (let i = 0; i < samples.length; i++) {\n      let sample = samples[i];\n      let originalDts = sample.dts - this._dtsBase;\n      let isKeyframe = sample.isKeyframe;\n      let dts = originalDts - dtsCorrection;\n      let cts = sample.cts;\n      let pts = dts + cts;\n\n      if (firstDts === -1) {\n        firstDts = dts;\n        firstPts = pts;\n      }\n\n      let sampleDuration = 0;\n\n      if (i !== samples.length - 1) {\n        let nextDts = samples[i + 1].dts - this._dtsBase - dtsCorrection;\n        sampleDuration = nextDts - dts;\n      } else {\n        // the last sample\n        if (lastSample != null) {\n          // use stashed sample's dts to calculate sample duration\n          let nextDts = lastSample.dts - this._dtsBase - dtsCorrection;\n          sampleDuration = nextDts - dts;\n        } else if (mp4Samples.length >= 1) {\n          // use second last sample duration\n          sampleDuration = mp4Samples[mp4Samples.length - 1].duration;\n        } else {\n          // the only one sample, use reference sample duration\n          sampleDuration = Math.floor(this._videoMeta.refSampleDuration);\n        }\n      }\n\n      if (isKeyframe) {\n        let syncPoint = new SampleInfo(dts, pts, sampleDuration, sample.dts, true);\n        syncPoint.fileposition = sample.fileposition;\n        info.appendSyncPoint(syncPoint);\n      }\n\n      mp4Samples.push({\n        dts: dts,\n        pts: pts,\n        cts: cts,\n        units: sample.units,\n        size: sample.length,\n        isKeyframe: isKeyframe,\n        duration: sampleDuration,\n        originalDts: originalDts,\n        flags: {\n          isLeading: 0,\n          dependsOn: isKeyframe ? 2 : 1,\n          isDependedOn: isKeyframe ? 1 : 0,\n          hasRedundancy: 0,\n          isNonSync: isKeyframe ? 0 : 1\n        }\n      });\n    } // allocate mdatbox\n\n\n    mdatbox = new Uint8Array(mdatBytes);\n    mdatbox[0] = mdatBytes >>> 24 & 0xFF;\n    mdatbox[1] = mdatBytes >>> 16 & 0xFF;\n    mdatbox[2] = mdatBytes >>> 8 & 0xFF;\n    mdatbox[3] = mdatBytes & 0xFF;\n    mdatbox.set(MP4.types.mdat, 4); // Write samples into mdatbox\n\n    for (let i = 0; i < mp4Samples.length; i++) {\n      let units = mp4Samples[i].units;\n\n      while (units.length) {\n        let unit = units.shift();\n        let data = unit.data;\n        mdatbox.set(data, offset);\n        offset += data.byteLength;\n      }\n    }\n\n    let latest = mp4Samples[mp4Samples.length - 1];\n    lastDts = latest.dts + latest.duration;\n    lastPts = latest.pts + latest.duration;\n    this._videoNextDts = lastDts; // fill media segment info & add to info list\n\n    info.beginDts = firstDts;\n    info.endDts = lastDts;\n    info.beginPts = firstPts;\n    info.endPts = lastPts;\n    info.originalBeginDts = mp4Samples[0].originalDts;\n    info.originalEndDts = latest.originalDts + latest.duration;\n    info.firstSample = new SampleInfo(mp4Samples[0].dts, mp4Samples[0].pts, mp4Samples[0].duration, mp4Samples[0].originalDts, mp4Samples[0].isKeyframe);\n    info.lastSample = new SampleInfo(latest.dts, latest.pts, latest.duration, latest.originalDts, latest.isKeyframe);\n\n    if (!this._isLive) {\n      this._videoSegmentInfoList.append(info);\n    }\n\n    track.samples = mp4Samples;\n    track.sequenceNumber++; // workaround for chrome < 50: force first sample as a random access point\n    // see https://bugs.chromium.org/p/chromium/issues/detail?id=229412\n\n    if (this._forceFirstIDR) {\n      let flags = mp4Samples[0].flags;\n      flags.dependsOn = 2;\n      flags.isNonSync = 0;\n    }\n\n    let moofbox = MP4.moof(track, firstDts);\n    track.samples = [];\n    track.length = 0;\n\n    this._onMediaSegment('video', {\n      type: 'video',\n      data: this._mergeBoxes(moofbox, mdatbox).buffer,\n      sampleCount: mp4Samples.length,\n      info: info\n    });\n  }\n\n  _mergeBoxes(moof, mdat) {\n    let result = new Uint8Array(moof.byteLength + mdat.byteLength);\n    result.set(moof, 0);\n    result.set(mdat, moof.byteLength);\n    return result;\n  }\n\n}\n\nexport default MP4Remuxer;","map":null,"metadata":{},"sourceType":"module"}